{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Machine Learning - Workspace\\Avalon\\Final-Project-Avalon\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Code\\Machine Learning - Workspace\\Avalon\\Final-Project-Avalon\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ASUS\\.cache\\huggingface\\hub\\models--t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multi-hop Retrieval ===\n",
      "Context: Teorema Pythagoras: a² + b² = c²\n",
      "Teorema Pythagoras: a² + b² = c²\n",
      "Solution: Teorema Pythagoras: a2 + b2 = c2 Teorema Pythagoras: a2 + b2 = c2 Jika x2 + 5x + 6 = 0, berapa nilai x?\n",
      "\n",
      "=== Chain-of-Thought ===\n",
      "Solution: x2 + 5x + 6 = 0. Selesaikan masalah matematika berikut dengan langkah-langkah: Jika x2 + 5x + 6 = 0, berapa nilai x? Langkah 1: Pertama, pertama, pertama, pertama, pertama, pertama, pertama, pertama, pertama, pertama, pertama, pertama, pertama, pertama, pertama, pertama,\n",
      "\n",
      "=== Evaluasi ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:05<00:00,  5.46s/it]\n",
      "100%|██████████| 100/100 [10:08<00:00,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi CoT: 0.00\n",
      "Akurasi Multi-hop: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    pipeline,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Persiapan Dataset\n",
    "dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "train_data = dataset['train'].shuffle(seed=42)\n",
    "test_data = dataset['test'].shuffle(seed=42).select(range(100))  # Contoh 100 data uji\n",
    "\n",
    "# 2. Inisialisasi Model\n",
    "class MathSolver:\n",
    "    def __init__(self):\n",
    "        # MathBERT untuk retrieval\n",
    "        self.mathbert = BertModel.from_pretrained('tbs17/MathBERT')\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained('tbs17/MathBERT')\n",
    "        \n",
    "        # T5 untuk CoT generation\n",
    "        self.cot_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "        self.cot_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "        \n",
    "        # Knowledge base untuk multi-hop\n",
    "        self.knowledge_base = self._init_knowledge_base()\n",
    "        \n",
    "    def _init_knowledge_base(self):\n",
    "        \"\"\"Inisialisasi contoh knowledge base matematika\"\"\"\n",
    "        return {\n",
    "            'aljabar': [\n",
    "                \"Rumus kuadrat: ax² + bx + c = 0 → x = [-b ± √(b²-4ac)]/(2a)\",\n",
    "                \"Sistem persamaan: Untuk menyelesaikan sistem persamaan, gunakan substitusi atau eliminasi\"\n",
    "            ],\n",
    "            'geometri': [\n",
    "                \"Luas lingkaran = πr²\",\n",
    "                \"Teorema Pythagoras: a² + b² = c²\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # 3. Multi-hop Retrieval System\n",
    "    def retrieve_information(self, question, hops=2):\n",
    "        \"\"\"Sistem retrieval multi-hop sederhana\"\"\"\n",
    "        embeddings = self._get_bert_embeddings(question)\n",
    "        \n",
    "        # Cari topik relevan\n",
    "        topic_similarities = {}\n",
    "        for topic in self.knowledge_base:\n",
    "            topic_emb = self._get_bert_embeddings(topic)\n",
    "            topic_similarities[topic] = cosine_similarity(embeddings, topic_emb)\n",
    "            \n",
    "        selected_topic = max(topic_similarities, key=topic_similarities.get)\n",
    "        \n",
    "        # Lakukan hop kedua\n",
    "        context = []\n",
    "        for _ in range(hops):\n",
    "            best_match = max(\n",
    "                self.knowledge_base[selected_topic],\n",
    "                key=lambda x: cosine_similarity(\n",
    "                    self._get_bert_embeddings(x),\n",
    "                    embeddings\n",
    "                )\n",
    "            )\n",
    "            context.append(best_match)\n",
    "            embeddings = self._get_bert_embeddings(best_match)\n",
    "            \n",
    "        return \"\\n\".join(context)\n",
    "    \n",
    "    def _get_bert_embeddings(self, text):\n",
    "        \"\"\"Ekstrak embeddings dari MathBERT\"\"\"\n",
    "        inputs = self.bert_tokenizer(\n",
    "            text, \n",
    "            return_tensors='pt',\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = self.mathbert(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "    \n",
    "    # 4. Chain-of-Thought Generator\n",
    "    def generate_cot_solution(self, question):\n",
    "        \"\"\"Generate solusi dengan CoT\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Selesaikan masalah matematika berikut dengan langkah-langkah:\n",
    "        {question}\n",
    "        Langkah 1: Pertama, \n",
    "        \"\"\"\n",
    "        inputs = self.cot_tokenizer(\n",
    "            prompt,\n",
    "            return_tensors='pt',\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        outputs = self.cot_model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_length=512,\n",
    "            num_beams=5,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        \n",
    "        return self.cot_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 5. Evaluasi\n",
    "    def evaluate(self, method='cot', test_data=test_data):\n",
    "        \"\"\"Evaluasi performa model\"\"\"\n",
    "        correct = 0\n",
    "        for example in tqdm(test_data):\n",
    "            question = example['question']\n",
    "            true_answer = example['answer']\n",
    "\n",
    "            if method == 'cot':\n",
    "                solution = self.generate_cot_solution(question)\n",
    "            else:\n",
    "                context = self.retrieve_information(question)\n",
    "                solution = self.generate_cot_solution(context + \"\\n\" + question)\n",
    "\n",
    "            if self._compare_answers(solution, true_answer):\n",
    "                correct += 1\n",
    "\n",
    "        return correct / len(test_data)\n",
    "    \n",
    "    def _compare_answers(self, pred, true):\n",
    "        \"\"\"Perbandingan jawaban sederhana\"\"\"\n",
    "        pred = pred.strip().lower()\n",
    "        true = true.strip().lower()\n",
    "        return true in pred\n",
    "\n",
    "# 6. Eksekusi Utama\n",
    "if __name__ == \"__main__\":\n",
    "    solver = MathSolver()\n",
    "    \n",
    "    # Contoh penggunaan\n",
    "    problem = \"Jika x² + 5x + 6 = 0, berapa nilai x?\"\n",
    "    \n",
    "    # Multi-hop\n",
    "    print(\"=== Multi-hop Retrieval ===\")\n",
    "    context = solver.retrieve_information(problem)\n",
    "    print(\"Context:\", context)\n",
    "    print(\"Solution:\", solver.generate_cot_solution(context + \"\\n\" + problem))\n",
    "    \n",
    "    # CoT\n",
    "    print(\"\\n=== Chain-of-Thought ===\")\n",
    "    print(\"Solution:\", solver.generate_cot_solution(problem))\n",
    "    \n",
    "    # Evaluasi\n",
    "    print(\"\\n=== Evaluasi ===\")\n",
    "    cot_acc = solver.evaluate('cot')\n",
    "    retrieval_acc = solver.evaluate('retrieval')\n",
    "    print(f\"Akurasi CoT: {cot_acc:.2f}\")\n",
    "    print(f\"Akurasi Multi-hop: {retrieval_acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
